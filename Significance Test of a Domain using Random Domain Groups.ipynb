{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "class Gender_Bias():\n",
    "\n",
    "\n",
    "    def __init__(self, domains):\n",
    "\n",
    "        self.weat_file_path = \"dataset/en_weat_file.txt\"\n",
    "        self.word_file_path = \"dataset/\" + str(1900) + \"-vocab.pkl\"\n",
    "        self.embedding_file_path = \"dataset/\"\n",
    "        self.domains = domains\n",
    "\n",
    "\n",
    "    def load_embeddings(self, start, end):\n",
    "\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.word_list = pickle.load(open(self.word_file_path, \"rb\"))\n",
    "        self.word_dic = dict({(x, i) for (i,x) in enumerate(self.word_list)})\n",
    "\n",
    "        self.word2vec_pkl = {}\n",
    "        self.word2vec_npy = {}\n",
    "\n",
    "        for year in range(start, end, 10):\n",
    "            word_file_name = str(1800+year) + \"-vocab.pkl\"\n",
    "            word_list = pickle.load(open(self.embedding_file_path + word_file_name, \"rb\"))\n",
    "            word_dic = dict({(x, i) for (i,x) in enumerate(word_list)})\n",
    "\n",
    "            vec_file_name = str(1800+year) + \"-w.npy\"\n",
    "            word_vec = np.load(self.embedding_file_path + vec_file_name)\n",
    "\n",
    "            self.word2vec_pkl[str(1800+year)] = word_list\n",
    "            self.word2vec_npy[str(1800+year)] = word_vec\n",
    "\n",
    "\n",
    "    def load_weat_words(self, female_topic=\"WEAT_Topic_Female\", male_topic=\"WEAT_Topic_Male\"):\n",
    "\n",
    "        file_read = open(self.weat_file_path, \"r\")\n",
    "        topic_dict = {}\n",
    "\n",
    "        print(\"WEAT Dataset Loading\")\n",
    "\n",
    "        for line in file_read:\n",
    "            data = line.strip().split(\", \")\n",
    "            current_topic = data[0]\n",
    "\n",
    "            if current_topic in self.domains:\n",
    "                topic_dict[current_topic] = [x.lower() for x in data[1:]]\n",
    "                print(current_topic, topic_dict[current_topic])\n",
    "\n",
    "        self.female_domain = [female_topic] + topic_dict[female_topic]\n",
    "        self.male_domain = [male_topic] + topic_dict[male_topic]\n",
    "\n",
    "        del topic_dict[female_topic]\n",
    "        del topic_dict[male_topic]\n",
    "        self.domain_dict = topic_dict\n",
    "\n",
    "            \n",
    "    def randomize_weat_words(self):\n",
    "\n",
    "        for domain in self.domain_dict:\n",
    "            data_list = []\n",
    "            for k in range(len(self.domain_dict[domain])):\n",
    "                randind = np.random.randint(0, len(self.word_list))\n",
    "                data_list.append(self.word_list[randind])\n",
    "\n",
    "            self.domain_dict[domain] = data_list\n",
    "\n",
    "\n",
    "    def average_similarity_word_vs_domain(self, word_one, given_list, start, end, method=\"l1\"):\n",
    "\n",
    "        wordsim = []\n",
    "        for year in range(start, end, 10):\n",
    "            word_list = self.word2vec_pkl[str(1800+year)]\n",
    "            word_dic = dict({(x, i) for (i,x) in enumerate(word_list)})\n",
    "\n",
    "            word_vec = self.word2vec_npy[str(1800+year)]\n",
    "\n",
    "            similarity = []\n",
    "            for word_two in given_list: #[\"lesbian\"]:\n",
    "                try:\n",
    "                    vec_one = np.array(word_vec[word_dic[word_one]])\n",
    "                    vec_two = np.array(word_vec[word_dic[word_two]])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if method == \"l1\":\n",
    "                    sim = cosine_similarity([vec_one], [vec_two])\n",
    "                else:\n",
    "                    sim = euclidean_distances([vec_one], [vec_two])\n",
    "                similarity.append(sim[0][0])\n",
    "\n",
    "            wordsim.append(np.average(similarity))\n",
    "        \n",
    "        #print(\"Returning Wordsim: \", len(wordsim))\n",
    "        return wordsim\n",
    "    \n",
    "    \n",
    "    def average_centroid_of_domain_vs_word(self, word_one, given_list, start, end, method=\"l1\"):\n",
    "\n",
    "        wordsim = []\n",
    "        for year in range(start, end, 10):\n",
    "            word_list = self.word2vec_pkl[str(1800+year)]\n",
    "            word_dic = dict({(x, i) for (i,x) in enumerate(word_list)})\n",
    "\n",
    "            word_vec = self.word2vec_npy[str(1800+year)]\n",
    "\n",
    "            vectors = []\n",
    "            for word_two in given_list:\n",
    "                try:\n",
    "                    vec_two = np.array(word_vec[word_dic[word_two]])\n",
    "                    vectors.append(vec_two)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            vec_one = np.array(word_vec[word_dic[word_one]])\n",
    "            vectors = np.array(vectors)\n",
    "            centroid = np.average(vectors, axis=0)\n",
    "            \n",
    "            if method == \"l1\":\n",
    "                sim = cosine_similarity([vec_one], [centroid])\n",
    "            else:\n",
    "                sim = euclidean_distances([vec_one], [centroid])\n",
    "\n",
    "            wordsim.append(sim[0][0])\n",
    "\n",
    "        return wordsim\n",
    "\n",
    "\n",
    "    def gender_vs_domains(self, word, group=\"general\", method=\"l1\"):\n",
    "\n",
    "        domain_similarity = {}\n",
    "\n",
    "        for domain in self.domain_dict:\n",
    "            word_list = self.domain_dict[domain]\n",
    "            if group == \"general\":\n",
    "                avg_sim = self.average_similarity_word_vs_domain(word, word_list, self.start, self.end, method)\n",
    "            else:\n",
    "                avg_sim = self.average_centroid_of_domain_vs_word(word, word_list, self.start, self.end, method)\n",
    "            \n",
    "            domain_similarity[domain] = avg_sim\n",
    "\n",
    "        return domain_similarity\n",
    "\n",
    "\n",
    "    def return_gender_stats(self, gender_list, group=\"general\", method=\"l1\"):\n",
    "\n",
    "        gender_association = {}\n",
    "\n",
    "        for word in gender_list:\n",
    "            domain_similarity = self.gender_vs_domains(word, group, method)\n",
    "            gender_association[word] = domain_similarity\n",
    "            #print(\"\\tDomain Similarity\", len(domain_similarity))\n",
    "            \n",
    "        return gender_association\n",
    "            \n",
    "    \n",
    "    def create_data_store_stats(self, group=\"general\", method=\"l1\"): #or centroid, l2\n",
    "\n",
    "        self.data_store = {}\n",
    "        self.data_store[self.female_domain[0]] = self.return_gender_stats(self.female_domain[1:], group, method)\n",
    "        self.data_store[self.male_domain[0]] = self.return_gender_stats(self.male_domain[1:], group, method)\n",
    "        \n",
    "    \n",
    "    def dispersion_in_word_domain(self, given_list, start, end, dispersion=\"average\", method=\"l2\"):\n",
    "\n",
    "        wordsim = []\n",
    "        for year in range(start, end, 10):\n",
    "            word_list = self.word2vec_pkl[str(1800+year)]\n",
    "            word_dic = dict({(x, i) for (i,x) in enumerate(word_list)})\n",
    "\n",
    "            word_vec = self.word2vec_npy[str(1800+year)]\n",
    "\n",
    "            similarity = []\n",
    "            vectors = []\n",
    "            \n",
    "            for word_two in given_list: \n",
    "                try:\n",
    "                    vec = np.array(word_vec[word_dic[word_two]])\n",
    "                    vectors.append(vec)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            centroid = np.average(vectors, axis=0)\n",
    "            \n",
    "            for i in range(len(vectors)):\n",
    "                if method == \"l2\":\n",
    "                    sim = euclidean_distances([vectors[i]], [centroid])\n",
    "                else:\n",
    "                    sim = cosine_similarity([vectors[i]], [centroid])\n",
    "                    \n",
    "                similarity.append(sim[0][0])\n",
    "\n",
    "            if dispersion == \"average\":\n",
    "                wordsim.append(np.average(similarity))\n",
    "            else:\n",
    "                wordsim.append(np.var(similarity))\n",
    "\n",
    "        return wordsim\n",
    "    \n",
    "    \n",
    "    def compute_dispersion(self, dispersion=\"average\", method=\"l2\"): #Or average\n",
    "        \n",
    "        domain_similarity = {}\n",
    "        \n",
    "        for domain in self.domain_dict:\n",
    "            word_list = self.domain_dict[domain]\n",
    "            avg_sim = self.dispersion_in_word_domain(word_list, self.start, self.end, dispersion, method)\n",
    "            \n",
    "            domain_similarity[domain] = avg_sim\n",
    "            \n",
    "        return domain_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "color = [\"red\", \"green\", \"blue\", \"magenta\", \"brown\", \"cyan\"]\n",
    "marker = ['o', 's', 'p', 'd', '>', '<']\n",
    "weatset = [\"Family\", \"Career\", \"Science\", \"Arts\"] #, \"Math\", \"Weapons\"]\n",
    "\n",
    "\n",
    "def compute_bias_without_plot(gender_profile_lang, dispersion, method):\n",
    "\n",
    "    dispersion_list = []\n",
    "    domain_dispersion = gender_profile_lang.compute_dispersion(dispersion=dispersion, method=method)\n",
    "    #print(domain_dispersion)\n",
    "    \n",
    "    for subject in weatset[:]: #dataset:\n",
    "        dispersion_list.append(domain_dispersion[\"WEAT_Topic_\"+subject])\n",
    "        #print(subject, domain_dispersion[\"WEAT_Topic_\"+subject])\n",
    "\n",
    "    return dispersion_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average of Distance from Centroid within a Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEAT Dataset Loading\n",
      "WEAT_Topic_Career ['executive', 'management', 'professional', 'corporation', 'salary', 'office', 'business', 'career']\n",
      "WEAT_Topic_Family ['home', 'parents', 'children', 'family', 'cousins', 'marriage', 'wedding', 'relatives']\n",
      "WEAT_Topic_Arts ['poetry', 'art', 'dance', 'literature', 'novel', 'symphony', 'drama', 'sculpture', 'shakespeare']\n",
      "WEAT_Topic_Male ['he', 'his', 'man', 'male', 'boy', 'son', 'brother', 'father', 'uncle', 'gentleman']\n",
      "WEAT_Topic_Female ['she', 'her', 'woman', 'female', 'girl', 'daughter', 'sister', 'mother', 'aunt', 'lady']\n",
      "WEAT_Topic_Science ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#from plotting_utility import compute_bias_without_plot\n",
    "import time\n",
    "\n",
    "domains = [\"WEAT_Topic_Female\", \"WEAT_Topic_Male\", \"WEAT_Topic_Family\", \\\n",
    "                \"WEAT_Topic_Career\", \"WEAT_Topic_Science\", \"WEAT_Topic_Arts\"]\n",
    "\n",
    "gender_profile_lang = Gender_Bias(domains)\n",
    "gender_profile_lang.load_embeddings(start=0, end=200)\n",
    "\n",
    "gender_profile_lang.load_weat_words()\n",
    "#gender_profile_lang.create_data_store_stats()\n",
    "print(\"Done!\")\n",
    "\n",
    "domain_dispersion_year = []\n",
    "start = time.time()\n",
    "\n",
    "for k in range(0, 1250):\n",
    "    dispersion_list = compute_bias_without_plot(gender_profile_lang, \"average\", \"l2\")\n",
    "    domain_dispersion_year += dispersion_list\n",
    "    gender_profile_lang.randomize_weat_words()\n",
    "    #print(len(domain_dispersion_year))\n",
    "    #break\n",
    "    \n",
    "end = time.time()\n",
    "#print(end-start, len(domain_dispersion_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "color = [\"red\", \"green\", \"blue\", \"magenta\", \"brown\", \"cyan\"]\n",
    "marker = ['o', 's', 'p', 'd', '>', '<']\n",
    "weatset = [\"Family\", \"Career\", \"Science\", \"Arts\"] #, \"Math\", \"Weapons\"]\n",
    "year = [1800+x for x in range(gender_profile_lang.start, gender_profile_lang.end, 10)]\n",
    "\n",
    "for i in range(0, 4):\n",
    "    subject = weatset[i]\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(year, domain_dispersion_year[i])\n",
    "    \n",
    "    regress_assoc = slope * np.array(year) + intercept\n",
    "\n",
    "    plt.plot(regress_assoc, linestyle='-', linewidth=3, color=color[i])\n",
    "\n",
    "    plt.plot(domain_dispersion_year[i], color=color[i], marker=marker[i], ms=6, \\\n",
    "            linestyle='-', linewidth=4, alpha=0.4)\n",
    "    \n",
    "    plt.plot(domain_dispersion_year[i], label=subject, marker=marker[i], linewidth=0.1, \\\n",
    "             mfc=color[i], ms=6, mec='black', mew=1.25)\n",
    "    \n",
    "\n",
    "xaxis = [i for i in range(0, int((gender_profile_lang.end-gender_profile_lang.start)/10))]\n",
    "xtick = [1800+x for x in range(gender_profile_lang.start, gender_profile_lang.end, 10)]\n",
    "plt.xticks(xaxis, xtick, rotation=45)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0., 1.1, 1., .102), loc=4, \\\n",
    "        ncol=4, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting Histogram for Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "color = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "domain_dispersion_year = np.array(domain_dispersion_year)\n",
    "print(domain_dispersion_year.shape)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(len(year)):\n",
    "    #plt.figure(figsize=(4, 3))\n",
    "    plt.subplot(5,4,i+1)\n",
    "    plt.title(\"Average Distance from Centroid: \" + str(year[i]))\n",
    "    plt.ylabel(\"Count of Average Distance\")\n",
    "    \n",
    "    data = domain_dispersion_year[:, i]\n",
    "    plt.hist(data, bins=50)\n",
    "    \n",
    "    for k in range(4):\n",
    "        plt.axvline(data[k], linewidth=2., \\\n",
    "                color=color[k], label=weatset[k])\n",
    "    \n",
    "    plt.legend(loc=1)\n",
    "    #break\n",
    "    \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of Distance from Centroid within a Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from plotting_utility import compute_bias_without_plot\n",
    "import time\n",
    "\n",
    "domains = [\"WEAT_Topic_Female\", \"WEAT_Topic_Male\", \"WEAT_Topic_Family\", \\\n",
    "                \"WEAT_Topic_Career\", \"WEAT_Topic_Science\", \"WEAT_Topic_Arts\"]\n",
    "\n",
    "gender_profile_lang = Gender_Bias(domains)\n",
    "gender_profile_lang.load_embeddings(start=0, end=200)\n",
    "\n",
    "gender_profile_lang.load_weat_words()\n",
    "#gender_profile_lang.create_data_store_stats()\n",
    "print(\"Done!\")\n",
    "\n",
    "domain_dispersion_year = []\n",
    "start = time.time()\n",
    "\n",
    "for k in range(0, 1250):\n",
    "    dispersion_list = compute_bias_without_plot(gender_profile_lang, \"variance\", \"l2\")\n",
    "    domain_dispersion_year += dispersion_list\n",
    "    gender_profile_lang.randomize_weat_words()\n",
    "    #print(len(domain_dispersion_year))\n",
    "    #break\n",
    "    \n",
    "end = time.time()\n",
    "#print(end-start, len(domain_dispersion_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "color = [\"red\", \"green\", \"blue\", \"magenta\", \"brown\", \"cyan\"]\n",
    "marker = ['o', 's', 'p', 'd', '>', '<']\n",
    "weatset = [\"Family\", \"Career\", \"Science\", \"Arts\"] #, \"Math\", \"Weapons\"]\n",
    "year = [1800+x for x in range(gender_profile_lang.start, gender_profile_lang.end, 10)]\n",
    "\n",
    "for i in range(0, 4):\n",
    "    subject = weatset[i]\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(year, domain_dispersion_year[i])\n",
    "    \n",
    "    regress_assoc = slope * np.array(year) + intercept\n",
    "\n",
    "    plt.plot(regress_assoc, linestyle='-', linewidth=3, color=color[i])\n",
    "\n",
    "    plt.plot(domain_dispersion_year[i], color=color[i], marker=marker[i], ms=6, \\\n",
    "            linestyle='-', linewidth=4, alpha=0.4)\n",
    "    \n",
    "    plt.plot(domain_dispersion_year[i], label=subject, marker=marker[i], linewidth=0.1, \\\n",
    "             mfc=color[i], ms=6, mec='black', mew=1.25)\n",
    "    \n",
    "\n",
    "xaxis = [i for i in range(0, int((gender_profile_lang.end-gender_profile_lang.start)/10))]\n",
    "xtick = [1800+x for x in range(gender_profile_lang.start, gender_profile_lang.end, 10)]\n",
    "plt.xticks(xaxis, xtick, rotation=45)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0., 1.1, 1., .102), loc=4, \\\n",
    "        ncol=4, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting Histogram for Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "color = [\"red\", \"green\", \"blue\", \"black\"]\n",
    "domain_dispersion_year = np.array(domain_dispersion_year)\n",
    "print(domain_dispersion_year.shape)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(len(year)):\n",
    "    #plt.figure(figsize=(4, 3))\n",
    "    plt.subplot(5,4,i+1)\n",
    "    plt.title(\"Average Distance from Centroid: \" + str(year[i]))\n",
    "    plt.ylabel(\"Count of Average Distance\")\n",
    "    \n",
    "    data = domain_dispersion_year[:, i]\n",
    "    plt.hist(data, bins=50)\n",
    "    \n",
    "    for k in range(4):\n",
    "        plt.axvline(data[k], linewidth=2., \\\n",
    "                color=color[k], label=weatset[k])\n",
    "    \n",
    "    plt.legend(loc=1)\n",
    "    #break\n",
    "    \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test the Code Implementation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#from compute_gender_bias import Gender_Bias\n",
    "from plotting_utility import compute_bias_against_weat\n",
    "\n",
    "domains = [\"WEAT_Topic_Female\", \"WEAT_Topic_Male\", \"WEAT_Topic_Family\", \\\n",
    "                \"WEAT_Topic_Career\", \"WEAT_Topic_Science\", \"WEAT_Topic_Arts\"]\n",
    "\n",
    "\n",
    "gender_profile_lang = Gender_Bias(domains)\n",
    "gender_profile_lang.load_embeddings(start=0, end=200)\n",
    "\n",
    "gender_profile_lang.load_weat_words()\n",
    "gender_profile_lang.create_data_store_stats()\n",
    "print(\"Done!\")\n",
    "\n",
    "regression_params, bias_scores = compute_bias_against_weat(gender_profile_lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
